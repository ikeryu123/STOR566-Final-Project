{"cells":[{"cell_type":"code","execution_count":22,"metadata":{"id":"lWp1UCMKRDgZ","trusted":true},"outputs":[],"source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","import os\n","import pandas as pd\n","import joblib\n","from imutils import paths\n","from sklearn.preprocessing import LabelBinarizer\n","from tqdm import tqdm\n","import pandas as pd\n","import numpy as np\n","import random\n","import albumentations\n","import matplotlib.pyplot as plt\n","import argparse\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import time\n","from PIL import Image\n","from tqdm import tqdm\n","from torchvision import models as models\n","from sklearn.model_selection import train_test_split\n","from torch.utils.data import Dataset, DataLoader"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Computation device: cpu\n"]}],"source":["def seed_everything(SEED=42):\n","    random.seed(SEED)\n","    np.random.seed(SEED)\n","    torch.manual_seed(SEED)\n","    torch.cuda.manual_seed(SEED)\n","    torch.cuda.manual_seed_all(SEED)\n","    torch.backends.cudnn.benchmark = True \n","SEED=42\n","seed_everything(SEED=SEED)\n","''' SEED Everything '''\n","# set computation device\n","device = ('cuda:0' if torch.cuda.is_available() else 'cpu')\n","print(f\"Computation device: {device}\")"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["df = pd.read_csv('input/data.csv')\n","X = df.image_path.values\n","y = df.target.values\n","(xtrain, xtest, ytrain, ytest) = (train_test_split(X, y, \n","                                test_size=0.25, random_state=42))\n"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["# image dataset module\n","class NaturalImageDataset(Dataset):\n","    def __init__(self, path, labels, tfms=None):\n","        self.X = path\n","        self.y = labels\n","        # apply augmentations\n","        if tfms == 0: # if validating\n","            \n","            self.aug = albumentations.Compose([\n","                albumentations.Resize(72, 72, always_apply=True),\n","                albumentations.Normalize(mean=[0, 0, 0],\n","                          std=[1, 1, 1], always_apply=True)\n","                #albumentations.Normalize(mean=[0.485, 0.456, 0.406],\n","                #          std=[0.229, 0.224, 0.225], always_apply=True)\n","            ])\n","            '''\n","            self.aug = albumentations.Compose([\n","                albumentations.Resize(72, 72, always_apply=True)\n","            ])\n","            '''\n","        else: # if training\n","            \n","            self.aug = albumentations.Compose([\n","                albumentations.Resize(72, 72, always_apply=True),\n","                albumentations.Normalize(mean=[0, 0, 0],\n","                          std=[1, 1, 1], always_apply=True)\n","                #albumentations.Normalize(mean=[0.485, 0.456, 0.406],\n","                #          std=[0.229, 0.224, 0.225], always_apply=True)\n","            ])\n","            '''\n","            self.aug = albumentations.Compose([\n","                albumentations.Resize(72, 72, always_apply=True)\n","            ])\n","            '''\n","    def __len__(self):\n","        return (len(self.X))\n","    \n","    def __getitem__(self, i):\n","        image = Image.open(self.X[i])\n","        image = self.aug(image=np.array(image))['image']\n","        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n","        label = self.y[i]\n","        return torch.tensor(image, dtype=torch.float), torch.tensor(label, dtype=torch.long)\n","        "]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["train_data = NaturalImageDataset(xtrain, ytrain, tfms=1)\n","test_data = NaturalImageDataset(xtest, ytest, tfms=0)\n"," \n","# dataloaders\n","trainloader = DataLoader(train_data, batch_size=16, shuffle=True)\n","testloader = DataLoader(test_data, batch_size=16, shuffle=False)\n","\n","\n","classes = ('cbf', 'ccf', 'cff', 'cmbf', 'cmcf', 'cmff', 'obf', 'off', 'ombf', 'omcf', 'omff')\n"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"5PC5pCRTSBIv","trusted":true},"outputs":[],"source":["transform = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0, 0, 0],\n","                          std=[1, 1, 1]),\n","])"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":28497,"status":"ok","timestamp":1591945220774,"user":{"displayName":"Dr. Vaibhav Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggv0ODnZNPUUE1bFaIOUaFH9CpYqhZjPkcwn9lJqA=s64","userId":"18385588513169057983"},"user_tz":-330},"id":"_U7qLjdZc9ip","outputId":"b14b1536-ea0b-45f4-bc13-1857e37158aa","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Using cache found in C:\\Users\\22894/.cache\\torch\\hub\\pytorch_vision_v0.6.0\n","c:\\Users\\22894\\miniconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","c:\\Users\\22894\\miniconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"data":{"text/plain":["AlexNet(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n","    (1): ReLU(inplace=True)\n","    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (4): ReLU(inplace=True)\n","    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (7): ReLU(inplace=True)\n","    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (9): ReLU(inplace=True)\n","    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU(inplace=True)\n","    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n","  (classifier): Sequential(\n","    (0): Dropout(p=0.5, inplace=False)\n","    (1): Linear(in_features=9216, out_features=4096, bias=True)\n","    (2): ReLU(inplace=True)\n","    (3): Dropout(p=0.5, inplace=False)\n","    (4): Linear(in_features=4096, out_features=4096, bias=True)\n","    (5): ReLU(inplace=True)\n","    (6): Linear(in_features=4096, out_features=1000, bias=True)\n","  )\n",")"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["#Now using the AlexNet\n","AlexNet_Model = torch.hub.load('pytorch/vision:v0.6.0', 'alexnet', pretrained=True)\n","AlexNet_Model.eval()"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"hwO80p-tjv7M","trusted":true},"outputs":[],"source":["import torch.nn as nn\n","AlexNet_Model.classifier[1] = nn.Linear(9216,4096)\n","AlexNet_Model.classifier[4] = nn.Linear(4096,1024)\n","AlexNet_Model.classifier[6] = nn.Linear(1024,11)"]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":28963,"status":"ok","timestamp":1591945221260,"user":{"displayName":"Dr. Vaibhav Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggv0ODnZNPUUE1bFaIOUaFH9CpYqhZjPkcwn9lJqA=s64","userId":"18385588513169057983"},"user_tz":-330},"id":"J4_DnBMHkC-z","outputId":"0fea77c9-3856-4a84-d5d5-5b69f3811949","trusted":true},"outputs":[{"data":{"text/plain":["AlexNet(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n","    (1): ReLU(inplace=True)\n","    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (4): ReLU(inplace=True)\n","    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (7): ReLU(inplace=True)\n","    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (9): ReLU(inplace=True)\n","    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU(inplace=True)\n","    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n","  (classifier): Sequential(\n","    (0): Dropout(p=0.5, inplace=False)\n","    (1): Linear(in_features=9216, out_features=4096, bias=True)\n","    (2): ReLU(inplace=True)\n","    (3): Dropout(p=0.5, inplace=False)\n","    (4): Linear(in_features=4096, out_features=1024, bias=True)\n","    (5): ReLU(inplace=True)\n","    (6): Linear(in_features=1024, out_features=11, bias=True)\n","  )\n",")"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["AlexNet_Model.eval()"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"4flyxAl8dyIQ","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["cpu\n"]}],"source":["# move the input and model to GPU for speed if available\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"]},{"cell_type":"code","execution_count":32,"metadata":{"executionInfo":{"elapsed":37629,"status":"ok","timestamp":1591945229956,"user":{"displayName":"Dr. Vaibhav Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggv0ODnZNPUUE1bFaIOUaFH9CpYqhZjPkcwn9lJqA=s64","userId":"18385588513169057983"},"user_tz":-330},"id":"XgmBpBExrjwA","outputId":"90ed00a9-4d6e-4dc9-e79e-53bc92b3f909","trusted":true},"outputs":[{"data":{"text/plain":["AlexNet(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n","    (1): ReLU(inplace=True)\n","    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (4): ReLU(inplace=True)\n","    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (7): ReLU(inplace=True)\n","    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (9): ReLU(inplace=True)\n","    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU(inplace=True)\n","    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n","  (classifier): Sequential(\n","    (0): Dropout(p=0.5, inplace=False)\n","    (1): Linear(in_features=9216, out_features=4096, bias=True)\n","    (2): ReLU(inplace=True)\n","    (3): Dropout(p=0.5, inplace=False)\n","    (4): Linear(in_features=4096, out_features=1024, bias=True)\n","    (5): ReLU(inplace=True)\n","    (6): Linear(in_features=1024, out_features=11, bias=True)\n","  )\n",")"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["AlexNet_Model.to(device)"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"bM-BE171qrnn","trusted":true},"outputs":[],"source":["import torch.optim as optim\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(AlexNet_Model.parameters(), lr=0.001, momentum=0.9)"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"kMVBKdQcICcn","trusted":true},"outputs":[],"source":["import time"]},{"cell_type":"code","execution_count":35,"metadata":{"executionInfo":{"elapsed":3101657,"status":"ok","timestamp":1591957865577,"user":{"displayName":"Dr. Vaibhav Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggv0ODnZNPUUE1bFaIOUaFH9CpYqhZjPkcwn9lJqA=s64","userId":"18385588513169057983"},"user_tz":-330},"id":"vD_NM-4AdDiA","outputId":"c2370b0a-f809-42dd-e4ed-45811110d786","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-25-e7befafb6490>:43: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n","  return torch.tensor(image, dtype=torch.float), torch.tensor(label, dtype=torch.long)\n"]},{"name":"stdout","output_type":"stream","text":["[1,    31] loss: 0.036\n","Time: 7.292773246765137\n","[2,    31] loss: 0.028\n","Time: 7.312429189682007\n","[3,    31] loss: 0.025\n","Time: 6.954720735549927\n","[4,    31] loss: 0.019\n","Time: 7.5452880859375\n","[5,    31] loss: 0.016\n","Time: 6.9728991985321045\n","[6,    31] loss: 0.013\n","Time: 6.936319828033447\n","[7,    31] loss: 0.013\n","Time: 7.528712272644043\n","[8,    31] loss: 0.013\n","Time: 6.939567565917969\n","[9,    31] loss: 0.012\n","Time: 6.908871650695801\n","[10,    31] loss: 0.010\n","Time: 6.910248517990112\n","[11,    31] loss: 0.007\n","Time: 6.935791730880737\n","[12,    31] loss: 0.008\n","Time: 7.082688331604004\n","[13,    31] loss: 0.008\n","Time: 6.900808572769165\n","[14,    31] loss: 0.007\n","Time: 6.903846740722656\n","[15,    31] loss: 0.006\n","Time: 6.965021371841431\n","[16,    31] loss: 0.004\n","Time: 6.90781044960022\n","[17,    31] loss: 0.003\n","Time: 6.834610223770142\n","[18,    31] loss: 0.003\n","Time: 6.753209352493286\n","[19,    31] loss: 0.003\n","Time: 6.789526462554932\n","[20,    31] loss: 0.003\n","Time: 6.824777841567993\n","[21,    31] loss: 0.001\n","Time: 6.797511100769043\n","[22,    31] loss: 0.002\n","Time: 6.737030029296875\n","[23,    31] loss: 0.004\n","Time: 7.449498176574707\n","[24,    31] loss: 0.002\n","Time: 7.399758338928223\n","[25,    31] loss: 0.001\n","Time: 7.900912761688232\n","[26,    31] loss: 0.002\n","Time: 7.160506248474121\n","[27,    31] loss: 0.001\n","Time: 7.1386802196502686\n","[28,    31] loss: 0.001\n","Time: 7.2496912479400635\n","[29,    31] loss: 0.000\n","Time: 7.676405668258667\n","[30,    31] loss: 0.000\n","Time: 7.930827856063843\n","Finished Training of AlexNet\n"]}],"source":["for epoch in range(30):  # loop over the dataset multiple times\n","\n","    running_loss = 0.0\n","    start_time = time.time()\n","    for i, data in enumerate(trainloader, 0):\n","        # get the inputs; data is a list of [inputs, labels]\n","        inputs, labels = data[0].to(device), data[1].to(device)\n","\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # forward + backward + optimize\n","        output = AlexNet_Model(inputs)\n","        loss = criterion(output, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        #Time\n","        end_time = time.time()\n","        time_taken = end_time - start_time\n","\n","        # print statistics\n","        running_loss += loss.item()\n","        if i == 30:    # print every 2000 mini-batches\n","            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000))\n","            print('Time:',time_taken)\n","            running_loss = 0.0\n","print('Finished Training of AlexNet')"]},{"cell_type":"code","execution_count":39,"metadata":{"executionInfo":{"elapsed":31100,"status":"ok","timestamp":1591958041179,"user":{"displayName":"Dr. Vaibhav Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggv0ODnZNPUUE1bFaIOUaFH9CpYqhZjPkcwn9lJqA=s64","userId":"18385588513169057983"},"user_tz":-330},"id":"ZiZgc7PJBw1p","outputId":"28155bc6-cae8-493f-9236-008dfd6866bf","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-25-e7befafb6490>:43: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n","  return torch.tensor(image, dtype=torch.float), torch.tensor(label, dtype=torch.long)\n"]},{"name":"stdout","output_type":"stream","text":["correct = 132, total = 164\n","Accuracy = : 80.49 %\n"]}],"source":["#Testing Accuracy\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data in testloader:\n","        images, labels = data[0].to(device), data[1].to(device)\n","        outputs = AlexNet_Model(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","print(\"correct = {}, total = {}\".format(correct, total))\n","print('Accuracy = : %.2f %%' % (100 * correct / total))"]},{"cell_type":"code","execution_count":44,"metadata":{"executionInfo":{"elapsed":32567,"status":"ok","timestamp":1591958077862,"user":{"displayName":"Dr. Vaibhav Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggv0ODnZNPUUE1bFaIOUaFH9CpYqhZjPkcwn9lJqA=s64","userId":"18385588513169057983"},"user_tz":-330},"id":"Quvi9j-mC6Bx","outputId":"21e11c73-40ff-4f5c-8701-871a2b7c794c","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-25-e7befafb6490>:43: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n","  return torch.tensor(image, dtype=torch.float), torch.tensor(label, dtype=torch.long)\n"]},{"name":"stdout","output_type":"stream","text":["[12.0, 15.0, 15.0, 9.0, 11.0, 8.0, 15.0, 13.0, 10.0, 11.0, 13.0]\n","[12.0, 18.0, 16.0, 15.0, 17.0, 11.0, 16.0, 16.0, 12.0, 15.0, 16.0]\n","Accuracy of   cbf : 100 %\n","Accuracy of   ccf : 83 %\n","Accuracy of   cff : 93 %\n","Accuracy of  cmbf : 60 %\n","Accuracy of  cmcf : 64 %\n","Accuracy of  cmff : 72 %\n","Accuracy of   obf : 93 %\n","Accuracy of   off : 81 %\n","Accuracy of  ombf : 83 %\n","Accuracy of  omcf : 73 %\n","Accuracy of  omff : 81 %\n"]}],"source":["class_correct = list(0. for i in range(11))\n","class_total = list(0. for i in range(11))\n","with torch.no_grad():\n","    for data in testloader:\n","        images, labels = data[0].to(device), data[1].to(device)\n","        outputs = AlexNet_Model(images)\n","        _, predicted = torch.max(outputs, 1)\n","        c = (predicted == labels).squeeze()\n","        for i in range(labels.shape[0]):\n","            label = labels[i]\n","            class_correct[label] += c[i].item()\n","            class_total[label] += 1\n","print(class_correct)\n","print(class_total)\n","\n","for i in range(11):\n","    print('Accuracy of %5s : %2d %%' % (\n","        classes[i], 100 * class_correct[i] / class_total[i]))"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1196,"status":"ok","timestamp":1591958082384,"user":{"displayName":"Dr. Vaibhav Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggv0ODnZNPUUE1bFaIOUaFH9CpYqhZjPkcwn9lJqA=s64","userId":"18385588513169057983"},"user_tz":-330},"id":"grWH0zXJEqYY","outputId":"544b6ea3-f6ae-4975-c939-0c044ba0de1c","trusted":true},"outputs":[],"source":["#Verifying average accuracy of the network\n","avg = 0\n","for i in range(10):\n","  temp = (100 * class_correct[i] / class_total[i])\n","  avg = avg + temp\n","avg = avg/10\n","print('Average accuracy = ', avg)  "]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.5 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.5"},"vscode":{"interpreter":{"hash":"c1377e858e6cd76e8bc9f3c9dfab26e85b972589677cb2814d30ce0fe0b0e87f"}}},"nbformat":4,"nbformat_minor":4}
